{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPfPFfki2da7",
        "colab_type": "code",
        "outputId": "aa812a3c-9934-478c-e36c-c4df60953925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import pandas as pd\n",
        "!pip -q install imblearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline \n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qyVs2sOF2ZV",
        "colab_type": "code",
        "outputId": "e378c25d-95ec-42bd-9ddc-9dd7b2fa5792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd '/content'\n",
        "!wget https://datahack-prod.s3.amazonaws.com/sample_submission/sample_submission_1Sfyqeb.zip\n",
        "!wget https://datahack-prod.s3.amazonaws.com/train_file/train_u5jK80M.zip\n",
        "!wget https://datahack-prod.s3.amazonaws.com/test_file/test_3BA6GZX.zip\n",
        "!unzip sample_submission_1Sfyqeb.zip\n",
        "!unzip train_u5jK80M.zip\n",
        "!unzip test_3BA6GZX.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2019-08-21 09:36:49--  https://datahack-prod.s3.amazonaws.com/sample_submission/sample_submission_1Sfyqeb.zip\n",
            "Resolving datahack-prod.s3.amazonaws.com (datahack-prod.s3.amazonaws.com)... 52.219.66.8\n",
            "Connecting to datahack-prod.s3.amazonaws.com (datahack-prod.s3.amazonaws.com)|52.219.66.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81001 (79K) [application/zip]\n",
            "Saving to: ‘sample_submission_1Sfyqeb.zip’\n",
            "\n",
            "sample_submission_1 100%[===================>]  79.10K   160KB/s    in 0.5s    \n",
            "\n",
            "2019-08-21 09:36:50 (160 KB/s) - ‘sample_submission_1Sfyqeb.zip’ saved [81001/81001]\n",
            "\n",
            "--2019-08-21 09:36:52--  https://datahack-prod.s3.amazonaws.com/train_file/train_u5jK80M.zip\n",
            "Resolving datahack-prod.s3.amazonaws.com (datahack-prod.s3.amazonaws.com)... 52.219.66.8\n",
            "Connecting to datahack-prod.s3.amazonaws.com (datahack-prod.s3.amazonaws.com)|52.219.66.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2670660 (2.5M) [application/zip]\n",
            "Saving to: ‘train_u5jK80M.zip’\n",
            "\n",
            "train_u5jK80M.zip   100%[===================>]   2.55M  1.48MB/s    in 1.7s    \n",
            "\n",
            "2019-08-21 09:36:55 (1.48 MB/s) - ‘train_u5jK80M.zip’ saved [2670660/2670660]\n",
            "\n",
            "--2019-08-21 09:36:56--  https://datahack-prod.s3.amazonaws.com/test_file/test_3BA6GZX.zip\n",
            "Resolving datahack-prod.s3.amazonaws.com (datahack-prod.s3.amazonaws.com)... 52.219.62.8\n",
            "Connecting to datahack-prod.s3.amazonaws.com (datahack-prod.s3.amazonaws.com)|52.219.62.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577993 (564K) [application/zip]\n",
            "Saving to: ‘test_3BA6GZX.zip’\n",
            "\n",
            "test_3BA6GZX.zip    100%[===================>] 564.45K   568KB/s    in 1.0s    \n",
            "\n",
            "2019-08-21 09:36:58 (568 KB/s) - ‘test_3BA6GZX.zip’ saved [577993/577993]\n",
            "\n",
            "Archive:  sample_submission_1Sfyqeb.zip\n",
            "  inflating: sample_submission.csv   \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._sample_submission.csv  \n",
            "Archive:  train_u5jK80M.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test_3BA6GZX.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: __MACOSX/._test.csv     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmxPWB2r2nKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/train.csv')\n",
        "test=pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zj6c7N6GzeR",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM-Z9KZDGywK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process(df):\n",
        "  df['max_dpd']=df.loc[:,'m1':'m12'].max(axis=1)\n",
        "  df['dpd_count']=df.loc[:,'m1':'m12'].apply(lambda x: x>0).sum(axis=1)\n",
        "  df['dpd30_count']=df.loc[:,'m1':'m12'].apply(lambda x: x==1).sum(axis=1)\n",
        "  df['dpd30_plus']=df.loc[:,'m1':'m12'].apply(lambda x: x>1).sum(axis=1)\n",
        "  df['dpd60_count']=df.loc[:,'m1':'m12'].apply(lambda x: x==2).sum(axis=1)\n",
        "  df['dpd60_plus']=df.loc[:,'m1':'m12'].apply(lambda x: x>2).sum(axis=1)\n",
        "  df['dpd90_count']=df.loc[:,'m1':'m12'].apply(lambda x: x==3).sum(axis=1)\n",
        "  df['dpd90_plus']=df.loc[:,'m1':'m12'].apply(lambda x: x>3).sum(axis=1)\n",
        "  df['dpd120_count']=df.loc[:,'m1':'m12'].apply(lambda x: x==4).sum(axis=1)\n",
        "  df['dpd120_plus']=df.loc[:,'m1':'m12'].apply(lambda x: x>4).sum(axis=1)\n",
        "  df['dpd150_count']=df.loc[:,'m1':'m12'].apply(lambda x: x==5).sum(axis=1)\n",
        "  df['dpd150_plus']=df.loc[:,'m1':'m12'].apply(lambda x: x>5).sum(axis=1)\n",
        "  df['dpd180_count']=df.loc[:,'m1':'m12'].apply(lambda x: x==6).sum(axis=1)\n",
        "  df['dpd180_plus']=df.loc[:,'m1':'m12'].apply(lambda x: x>6).sum(axis=1)\n",
        "  df['first_payment_date']=pd.to_datetime(df['first_payment_date'],errors='coerce')\n",
        "  df['origination_date']=pd.to_datetime(df['origination_date'],errors='coerce')\n",
        "  df=df.drop(['loan_id'],axis=1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aac58irJW4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "process(train)\n",
        "process(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2HtNVR2Bf3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_feature_names = ['source','financial_institution','loan_purpose','first_payment_date','origination_date']\n",
        "train_enco=pd.get_dummies(train,columns=cat_feature_names)\n",
        "test_enco=pd.get_dummies(test,columns=cat_feature_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFzQE6Hn7ZMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train[feature_names]=train[feature_names].apply(LabelEncoder().fit_transform)\n",
        "#test[feature_names]=test[feature_names].apply(LabelEncoder().fit_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic8MtMST5hgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train_enco.drop(['loan_id','m13'],axis=1)\n",
        "y=train_enco['m13']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zi96szYriyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_enco=test_enco.drop(['loan_id'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLrt-YKv3Nju",
        "colab_type": "code",
        "outputId": "f41a8dc6-200b-439f-c753-504049043061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 123)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
        "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "original_Xtrain = original_Xtrain.values\n",
        "original_Xtest = original_Xtest.values\n",
        "original_ytrain = original_ytrain.values\n",
        "original_ytest = original_ytest.values\n",
        "\n",
        "\n",
        "# List to append the score and then find the average\n",
        "accuracy_lst = []\n",
        "precision_lst = []\n",
        "recall_lst = []\n",
        "f1_lst = []\n",
        "auc_lst = []\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline \n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "smt = SMOTE(sampling_strategy='minority',random_state=42)\n",
        "\n",
        "# A parameter grid for XGBoost\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],#'min_child_weight': [1, 5, 10],\n",
        "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        #'subsample': [0.6, 0.8, 1.0],\n",
        "        #'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        #'max_depth': [3, 4, 5],\n",
        "        #'learning_rate':[0.001,0.01,0.1,1] \n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=500, objective='binary:logistic',\n",
        "                    silent=False, nthread=1,random_state=123)\n",
        "\n",
        "\n",
        "xgb_cv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=10, n_jobs=-1)\n",
        "\n",
        "\n",
        "for train, test in skf.split(original_Xtrain, original_ytrain):\n",
        "    pipeline=Pipeline([('smt', smt), ('xgb', xgb_cv)])\n",
        "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
        "    best_est = xgb_cv.best_estimator_\n",
        "    prediction = best_est.predict(original_Xtrain[test])\n",
        "    \n",
        "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
        "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
        "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
        "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
        "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
        "    \n",
        "print('---' * 45)\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
        "print('---' * 45)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: [     0      1      2 ... 116055 116056 116057] Test: [     9     14     15 ... 116049 116050 116053]\n",
            "Train: [     0      2      3 ... 116053 116055 116056] Test: [     1     13     20 ... 116051 116054 116057]\n",
            "Train: [     0      1      4 ... 116054 116056 116057] Test: [     2      3      6 ... 116036 116038 116055]\n",
            "Train: [     0      1      2 ... 116054 116055 116057] Test: [     4      8     11 ... 116044 116048 116056]\n",
            "Train: [     1      2      3 ... 116055 116056 116057] Test: [     0      5     18 ... 116046 116047 116052]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRDeZ2pRlRDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skf = StratifiedKFold(n_splits=7, shuffle = True, random_state = 123)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
        "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "original_Xtrain = original_Xtrain.values\n",
        "original_Xtest = original_Xtest.values\n",
        "original_ytrain = original_ytrain.values\n",
        "original_ytest = original_ytest.values\n",
        "\n",
        "\n",
        "# List to append the score and then find the average\n",
        "accuracy_lst = []\n",
        "precision_lst = []\n",
        "recall_lst = []\n",
        "f1_lst = []\n",
        "auc_lst = []\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline \n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "smt = SMOTE(sampling_strategy='minority',random_state=42)\n",
        "\n",
        "\n",
        "# A parameter grid for XGBoost\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],#'min_child_weight': [1, 5, 10],\n",
        "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        #'subsample': [0.6, 0.8, 1.0],\n",
        "        #'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        #'max_depth': [3, 4, 5],\n",
        "        #'learning_rate':[0.001,0.01,0.1,1] \n",
        "        }\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=500, objective='binary:logistic',\n",
        "                    silent=False, nthread=1,random_state=123)\n",
        "\n",
        "\n",
        "xgb_cv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=10, n_jobs=-1)\n",
        "\n",
        "\n",
        "for train, test in skf.split(original_Xtrain, original_ytrain):\n",
        "    pipeline=Pipeline([('smt', smt), ('xgb', xgb_cv)])\n",
        "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
        "    best_est = xgb_cv.best_estimator_\n",
        "    prediction = best_est.predict(original_Xtrain[test])\n",
        "    \n",
        "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
        "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
        "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
        "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
        "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
        "    \n",
        "print('---' * 45)\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
        "print('---' * 45)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_0GoP1-lT67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 123)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
        "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "original_Xtrain = original_Xtrain.values\n",
        "original_Xtest = original_Xtest.values\n",
        "original_ytrain = original_ytrain.values\n",
        "original_ytest = original_ytest.values\n",
        "\n",
        "\n",
        "# List to append the score and then find the average\n",
        "accuracy_lst = []\n",
        "precision_lst = []\n",
        "recall_lst = []\n",
        "f1_lst = []\n",
        "auc_lst = []\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline \n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "smt = SMOTE(sampling_strategy='minority',random_state=42)\n",
        "\n",
        "\n",
        "# A parameter grid for XGBoost\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],#'min_child_weight': [1, 5, 10],\n",
        "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        #'subsample': [0.6, 0.8, 1.0],\n",
        "        #'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        #'max_depth': [3, 4, 5],\n",
        "        #'learning_rate':[0.001,0.01,0.1,1] \n",
        "        }\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=500, objective='binary:logistic',\n",
        "                    silent=False, nthread=1,random_state=123)\n",
        "\n",
        "\n",
        "xgb_cv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=10, n_jobs=-1)\n",
        "\n",
        "\n",
        "for train, test in skf.split(original_Xtrain, original_ytrain):\n",
        "    pipeline=Pipeline([('smt', smt), ('xgb', xgb_cv)])\n",
        "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
        "    best_est = xgb_cv.best_estimator_\n",
        "    prediction = best_est.predict(original_Xtrain[test])\n",
        "    \n",
        "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
        "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
        "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
        "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
        "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
        "    \n",
        "print('---' * 45)\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
        "print('---' * 45)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7vFH2LmlZXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skf = StratifiedKFold(n_splits=9, shuffle = True, random_state = 123)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
        "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "original_Xtrain = original_Xtrain.values\n",
        "original_Xtest = original_Xtest.values\n",
        "original_ytrain = original_ytrain.values\n",
        "original_ytest = original_ytest.values\n",
        "\n",
        "\n",
        "# List to append the score and then find the average\n",
        "accuracy_lst = []\n",
        "precision_lst = []\n",
        "recall_lst = []\n",
        "f1_lst = []\n",
        "auc_lst = []\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline \n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "smt = SMOTE(sampling_strategy='minority',random_state=42)\n",
        "\n",
        "\n",
        "# A parameter grid for XGBoost\n",
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],#'min_child_weight': [1, 5, 10],\n",
        "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        #'subsample': [0.6, 0.8, 1.0],\n",
        "        #'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        #'max_depth': [3, 4, 5],\n",
        "        #'learning_rate':[0.001,0.01,0.1,1] \n",
        "        }\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=500, objective='binary:logistic',\n",
        "                    silent=False, nthread=1,random_state=123)\n",
        "\n",
        "\n",
        "xgb_cv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=10, n_jobs=-1)\n",
        "\n",
        "\n",
        "for train, test in skf.split(original_Xtrain, original_ytrain):\n",
        "    pipeline=Pipeline([('smt', smt), ('xgb', xgb_cv)])\n",
        "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
        "    best_est = xgb_cv.best_estimator_\n",
        "    prediction = best_est.predict(original_Xtrain[test])\n",
        "    \n",
        "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
        "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
        "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
        "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
        "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
        "    \n",
        "print('---' * 45)\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
        "print('---' * 45)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG-BQy5zZCrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit=best_est.predict(test_enco.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0oGc00e9tAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample=pd.read_csv('/content/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx97Wklr-pXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbQJZHds-sHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample['m13']=submit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31iTpmVu_FoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample.to_csv('sample7.csv',index_label=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}